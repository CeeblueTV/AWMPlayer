<!DOCTYPE html>
<html lang="en">
<head>
    <title>AWM-player metadata example</title>
    <meta charset="utf-8">
    <meta content="13.08.2021~1" name="version">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
    <style>
        html {
            margin: 0;
            padding: 0;
            display: table;
            width: 100%;
            height: 100%;
        }

        body {
            color: white;
            background: #0f0f0f;
            margin: 0;
            padding: 0;
            display: flex;
            flex-flow: column nowrap;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
        }

        #container {
            position: relative;
        }

        .metadata {
            font-family: monospace;
            font-size: 15px;
            left: 3px;
            position: relative;
            display: block;
            color: #fff;
        }
    </style>
</head>
<body>
<div>
    <span id="protocol-caption" style="color: #DDDDDD"></span>
    <span id="resolution-caption" style="color: #DDDDDD"></span>
</div>
<div id="container">
    <span class="metadata" id="metadata" style="color: #DDDDDD"></span>
    <span class="metadata" id="metadata-additional" style="color: #DDDDDD"></span>
    <canvas id="screenshot"></canvas>

    <div class="awmvideo" id="adaptive-video-player"></div>
</div>

<script src="https://use.ntpjs.org/ntp.js" async defer></script>
<script src="../dist/player.js"></script>
<script>

  AwmSkins.default.css.skin = "../dist/skins/default.css";
  AwmSkins.dev.css.skin = "../dist/skins/dev.css";

  const protocolCaptionElement = document.getElementById("protocol-caption");
  const resolutionCaptionElement = document.getElementById("resolution-caption");
  const metadataElement = document.getElementById("metadata");
  const metadataAdditional = document.getElementById("metadata-additional");
  const screenshotElement = document.getElementById("screenshot");
  const ctx = screenshotElement.getContext("2d");
  const awmElement = document.getElementById("adaptive-video-player");

  const PROTOCOL_LABELS = {
    "webrtc": "WebRTC",
    "ws/video/mp4": "MP4ovWS",
    "html5/video/mp4": "MP4",
    "html5/application/vnd.apple.mpegurl": "HLS"
  };

  const PROTOCOL_CHANGE_EVENT = "protocol_name";
  let tracksList = {};

  let awm = {};

  let playerSessionEvent = {
    totalEvents: 0
  };

  let playerSession = {
    setEvent: function (eventName, event) {
      playerSession[eventName] = {
        ...playerSessionEvent,
        ...playerSession[eventName],
        lastMessage: event.message,
        lastTimeStamp: event.timeStamp
      };
      playerSession[eventName].totalEvents++;

      console.log(playerSession);
      console.log(awm);
    }
  };

  /**
   * Events that can be triggered by the player. A mix of standard and Ceeblue-specific events.
   * This (n) indicates that these events appear in this order at startup.
   *
   * HTMLMediaElement: Events
   * https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/
   * Ceeblue Ultra-Low Latency and Multi-Protocol Player API
   * https://trello-attachments.s3.amazonaws.com/5d0c898a53c2018d02c3bd25/5e9ef3f623bcca478a6d4bc9/7cec88a8a84c755895135470e001a033/CeeblueStreamingAWMPlayerAPIGuide.pdf
   */
  [
    "abort", // Is triggered when the resource was not fully loaded, but not as the result of an error
    "canplay", // Is triggered when the player can play the media, but estimates that not enough data has been loaded to play the media up to its end without having to stop for further buffering of content
    "canplaythrough", // Is triggered when the player can play the media, and estimates that enough data has been loaded to play the media up to its end without having to stop for further buffering of content
    "comboChosen", // Is triggered when the player has chosen a working playback and source combination; Ceeblue specific (2)
    "durationchange", // Is triggered when the duration in the timeline changes
    "emptied", // Is triggered when the media has become empty; for example, this event is sent if the media has already been loaded (or partially loaded), and the load() method is called to reload it
    "ended", // Is triggered when the playback has ended because the player has no data
    "error", // Is triggered when the player encountered an error
    "haveStreamInfo", // Is triggered when the player has retrieved the metadata of a stream; Ceeblue specific; (1)
    "initialized", // Is triggered when the player has been built; Ceeblue specific; (3)
    "initializeFailed", // Is triggered when the player cannot be build; Ceeblue specific; (3)
    "loadeddata", // Is triggered when the frame at the current playback position of the media has finished loading; often the first frame
    "loadedmetadata", // Is triggered when the video is loaded; (4)
    "loadstart", // Is triggered when the player has started to load a resource
    // "log", // Is triggered when the player logs a event; Ceeblue specific
    "metaUpdate_tracks", // ??? Ceeblue specific
    "monitor", // Is triggered when the monitor updates playback score
    "pause", // Is triggered when the user hits pause or the player was paused by
    "play", // Is triggered when the user hits play or autostart is enabled; (5)
    "playerUpdate_trackChanged", // Is triggered when a track has changed
    "playing", // Is triggered when the player is playing; (6)
    //"progress", // Is triggered periodically as the player loads a resource (Is triggered to often)
    "protocol_name",
    "ratechange", // Is triggered when the playback rate has changed
    "seeked", // Is triggered when seeking has ended
    "seeking", // Is triggered when the player is seeking
    "stalled", // Is triggered when the player is trying to fetch media data, but data is unexpectedly not forthcoming.
    "suspend", // Is triggered when media data loading has been suspended
    //"timeupdate", // Is triggered when the time indicated by the currentTime attribute has been updated (Is triggered to often)
    "volumechange", // Is triggered when the volume of the player is changed
    "waiting", // Is triggered when playback has stopped because of a temporary lack of data
  ].forEach(function (eventName) {
    awmElement.addEventListener(eventName, function (event) {
      switch (eventName) {
        case "playing":
          console.log(`  #> ${eventName} `, event.type, eventName === event.type);
          playerSession.setEvent(eventName, event);
          if (playerSession.play.totalEvents >= 1 && playerSession.playing.totalEvents >= 1) {
            playerSession.timeToPlaying = playerSession.playing.lastTimeStamp - playerSession.play.lastTimeStamp;
          }
          // Check if the player is playing for the first time to measure the time to first frame
          if (playerSession.play.totalEvents === 1 && playerSession.playing.totalEvents === 1) {
            if (playerSession.haveStreamInfo.totalEvents === 1 && playerSession.comboChosen.totalEvents === 1 && playerSession.initialized.totalEvents === 1) {
              playerSession.timeToFirstFrame = playerSession.playing.lastTimeStamp;
            }
          }
          break;

        case "playerUpdate_trackChanged":
          playerSession.setEvent(eventName, event);
          if (playerSession.haveStreamInfo.totalEvents >= 1 && event.message.type === "video") {
            let track = Object.values(playerSession.haveStreamInfo.lastMessage.meta.tracks).filter(e => e.idx === +event.message.trackid)[0];
            playerSession.videoBitrate_kbps = track.bps / 128;
          }
          break;

        default:
          //console.log("›››", eventName, event.timeStamp, "detail: " + JSON.stringify(event.detail), "message: " + JSON.stringify(event.message));
          playerSession.setEvent(eventName, event);
      }
    }, true);
  });

  // Event that fires when protocol changed. Return new protocol name
  awmElement.addEventListener(PROTOCOL_CHANGE_EVENT, function (event) {
    protocolCaptionElement.innerText = PROTOCOL_LABELS[event.message] || event.message;
  });
  awmElement.addEventListener("playerUpdate_trackChanged", ({ message }) => {
    console.log("playerUpdate_trackChanged", message.type);
    if (message.type === "audio") {
      return;
    }

    const track = Object.values(tracksList).filter(e => e.idx === +message.trackid)[0];
    if (track) {
      resolutionCaptionElement.innerText = `${track.width}x${track.height}`;
    }
  });
  // Logging setup (optional). Event that fires when something were logged
  awmElement.addEventListener("log", function (log) {
    console.log(">", log.message);
  });
  // Event that fires when got info from stream
  awmElement.addEventListener("haveStreamInfo", function (event) {
    tracksList = event.message.meta.tracks;
    console.log("Event: StreamInfo (", JSON.stringify(event.message), ")");
    onMetaUpdate(tracksList); // 1st Meta Update comes always from haveStreamInfo
  });
  awmElement.addEventListener("streamOffline", function (event) {
    console.log("Stream Offline");
  });
  awmElement.addEventListener("metaUpdate_tracks", function(event) {
    console.log("Updated metadatas :", event);
    onMetaUpdate(event.message.meta.tracks);
  });

  let metaTracks = {count: 0, updates: 0};
  function onMetaUpdate(tracks) {
    subscriptions = awm.reference && awm.reference.metaTrackSubscriptions;
    metaTracks.updates++;
    // Listen to new tracks
    for (let track in tracks) {
      track = tracks[track];
      if (track.type == "meta") {
        metaTracks[track.idx] = metaTracks.updates;
        if (subscriptions) { // trick to subscribe on the fly, not just at start
          if (track.idx in metaTracks)
            continue;
            subscriptions.add(track.idx, onMetadata);
        } else {
          options.subscribeToMetaTrack.push([track.idx, onMetadata]);
        }
        metaTracks.count++;
      }
    }
    // Remove old tracks
    for (let trackId in metaTracks) {
      if (!isNaN(trackId) && metaTracks[trackId] < metaTracks.updates) {
        delete metaTracks[trackId];
        metaTracks.count--;
        if (subscriptions) {
          subscriptions.remove(trackId, onMetadata);
        }
      }
    }
    console.log("Metadatas found :", metaTracks.count, "(updates index: "+metaTracks.updates+")");
  }

  function onMetadata(meta) {
    // console.log(meta);
    console.log("Sync diff: ", this.player.api.currentTime * 1000 - meta.time);

    try{
      screenshot.width = this.video.clientWidth;
      screenshot.height = 20;
      ctx.drawImage(this.video, 0, 0);
    }catch(e){console.error(e);}

    // TODO: make it generic, not related with "winfinity"
    if (meta.data && meta.data.winfinity) {
      var winfinityObj = meta.data.winfinity;
      if (typeof winfinityObj === "string") { // AMF metadatas?
        var winfinityJson = meta.data.winfinity.replace(/(\w+:)|(\w+ :)/g, function(str) {
          return "\"" + str.substring(0, str.length - 1) + "\":";
        });
        winfinityObj = JSON.parse(winfinityJson);
      }

      if (winfinityObj.timecode) {
        var browserTimestamp = new Date();
        var winfinityTimecode = new Date(winfinityObj.timecode);

        var latency = browserTimestamp - winfinityTimecode;

        var browserTimestampStr = browserTimestamp.toISOString().replace(/Z|T/g, " ").replace(/-/g, ":");
        var winfinityTimecodeStr = winfinityTimecode.toISOString().replace(/Z|T/g, " ").replace(/-/g, ":");

        metadataElement.innerHTML = `${latency}ms (LATENCY)<br/>${winfinityTimecodeStr}(TIMECODE)<br/>${browserTimestampStr}&nbsp(BROWSER)<br/>`;
      } 
      // Additional attributes
      winfinityObj.timecode = undefined;
      const jsonMessages = JSON.stringify(winfinityObj);
      if (jsonMessages.length > 2) {
        metadataAdditional.innerHTML = "Additional metadatas : " + jsonMessages;
      }
    }
  }

  // Parse query options
  let query = new URLSearchParams(location.search);

  let options = {
    //The host from which the stream will be received
    host: "https://fly.live.ceeblue.tv:4433/",
    // Target element in which player would be placed
    target: awmElement,
    // Enable autoplay
    autoplay: true,
    skin: "dev",
    AwmVideoObject: awm,
    // Protocols and it"s priority
    forcePriority: {
      source: [
        ["type", [query.get("source") || "webrtc"]],
      ]
    },
    forceTrack: true,
    // Observe stream and change quality/protocol if needed.
    monitor: {
      // Here you can add fields to override them in monitor (default AdjustableMonitor monitor). If any function would be here it just replace AdjustableMonitor;
      PROTOCOL_CHANGE_EVENT, // Override event"s name that shoots when protocol initialized or changed
    },
    subscribeToMetaTrack: [] // Will be fulfilled when getting event haveStreamInfo
  };

  // Name of stream that would be played
  const streamName = query.get("streamName") || "xxx";
  options.accessToken = query.get("token") || "9b23465e-8f01-40ba-bef6-2bb338c05c01";
  awmPlay(streamName, options);
</script>
</body>
</html>
